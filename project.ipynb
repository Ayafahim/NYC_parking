{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Cell 1: Geocoding Parking Violations with Mapbox\n",
    "This cell samples 60,000 NYC parking violations, builds clean address strings, and geocodes them to latitude/longitude using the Mapbox API.\n",
    "To avoid geocoding the same address multiple times, it maintains a local geocode_cache.json that stores results.\n",
    "Coordinates are filtered to NYC bounds and exported to geocoded_fines_sample_50k.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geocoding 0 new addresses from 60,000 fines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final geocode cache saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Geocoded fines saved: 30,164 rows with coordinates.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mapbox import Geocoder\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# ----------------------------------------\n",
    "# CONFIGURATION\n",
    "# ----------------------------------------\n",
    "MAPBOX_TOKEN = \"pk.eyJ1IjoiYXlhZmFoaW0iLCJhIjoiY21haDI0NzNtMDZnYjJrc2did2ozb2diMSJ9.ucfbzSq_1BEtyk7jqGJb1g\"\n",
    "CSV_PATH = \"data/nyc_parking_violations_sample.csv\"\n",
    "CACHE_PATH = \"geocode_cache.json\"\n",
    "BACKUP_PATH = \"geocode_cache_backup.json\"\n",
    "SAVE_EVERY = 1000\n",
    "SLEEP_TIME = 0.05  # Be respectful\n",
    "SAMPLE_SIZE = 60000\n",
    "\n",
    "# ----------------------------------------\n",
    "# LOAD & SAMPLE DATA\n",
    "# ----------------------------------------\n",
    "cols = ['house_number', 'street_name', 'violation_county']\n",
    "df = pd.read_csv(CSV_PATH, usecols=cols, low_memory=False)\n",
    "df = df.dropna(subset=cols).sample(SAMPLE_SIZE, random_state=42)\n",
    "\n",
    "# Create full address\n",
    "df['full_address'] = df['house_number'].astype(str) + \" \" + df['street_name'] + \", \" + df['violation_county'] + \", NYC\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# LOAD OR CREATE CACHE\n",
    "# ----------------------------------------\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    with open(CACHE_PATH, \"r\") as f:\n",
    "        cache = json.load(f)\n",
    "else:\n",
    "    cache = {}\n",
    "\n",
    "# ----------------------------------------\n",
    "# SETUP GEOCODER\n",
    "# ----------------------------------------\n",
    "geocoder = Geocoder(access_token=MAPBOX_TOKEN)\n",
    "\n",
    "# Deduplicate addresses and filter out already cached ones\n",
    "unique_addresses = df['full_address'].unique()\n",
    "uncached = [addr for addr in unique_addresses if addr not in cache]\n",
    "print(f\"Geocoding {len(uncached):,} new addresses from {SAMPLE_SIZE:,} fines...\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# GEOCODE LOOP\n",
    "# ----------------------------------------\n",
    "for i, addr in enumerate(tqdm(uncached)):\n",
    "    try:\n",
    "        response = geocoder.forward(addr, limit=1)\n",
    "        features = response.geojson().get('features', [])\n",
    "        if features:\n",
    "            coords = features[0]['geometry']['coordinates']\n",
    "            cache[addr] = [coords[1], coords[0]]  # lat, lon\n",
    "        else:\n",
    "            cache[addr] = [None, None]\n",
    "    except Exception:\n",
    "        cache[addr] = [None, None]\n",
    "    time.sleep(SLEEP_TIME)\n",
    "\n",
    "    # Save progress\n",
    "    if (i + 1) % SAVE_EVERY == 0:\n",
    "        with open(CACHE_PATH, \"w\") as f:\n",
    "            json.dump(cache, f)\n",
    "        with open(BACKUP_PATH, \"w\") as f:\n",
    "            json.dump(cache, f)\n",
    "        print(f\"üíæ Checkpoint saved at {i+1} geocoded\")\n",
    "\n",
    "# Final save\n",
    "with open(CACHE_PATH, \"w\") as f:\n",
    "    json.dump(cache, f)\n",
    "with open(BACKUP_PATH, \"w\") as f:\n",
    "    json.dump(cache, f)\n",
    "print(\"‚úÖ Final geocode cache saved.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# APPLY GEOCOORDINATES TO DATAFRAME\n",
    "# ----------------------------------------\n",
    "df[['lat', 'lon']] = df['full_address'].apply(lambda x: pd.Series(cache.get(x, [None, None])))\n",
    "\n",
    "# Filter to valid NYC area\n",
    "df = df.dropna(subset=['lat', 'lon'])\n",
    "df = df[(df['lat'].between(40.49, 40.92)) & (df['lon'].between(-74.26, -73.68))]\n",
    "\n",
    "# Save final dataset\n",
    "df.to_csv(\"geocoded_fines_sample_50k.csv\", index=False)\n",
    "print(f\"‚úÖ Geocoded fines saved: {len(df):,} rows with coordinates.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Cell 2: Spatial Join ‚Äì Mapping Fines to Neighborhoods\n",
    "This cell reads the geocoded fines and converts them into a GeoDataFrame.\n",
    "It then loads the Neighborhood Tabulation Areas (NTA) from a GeoJSON file, reprojects it to the same coordinate system, and performs a spatial join to attach each fine to a neighborhood (if it intersects spatially)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  house_number    street_name   boroname                              ntaname\n",
      "0          290       Broadway   Brooklyn                         Williamsburg\n",
      "1            E  Lefferts Blvd     Queens                     South Ozone Park\n",
      "2          489       LENOX RD   Brooklyn                East Flatbush-Erasmus\n",
      "3           30      E 18th St  Manhattan  Midtown South-Flatiron-Union Square\n",
      "4          320   Atlantic Ave   Brooklyn  Downtown Brooklyn-DUMBO-Boerum Hill\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Load geocoded fine data\n",
    "df = pd.read_csv(\"geocoded_fines_sample_50k.csv\")\n",
    "\n",
    "# Filter to NYC bounds (just in case)\n",
    "# df = df[(df['lat'].between(40.49, 40.92)) & (df['lon'].between(-74.26, -73.68))]\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df['lon'], df['lat']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# ‚úÖ Load the clean GeoJSON instead of the shapefile\n",
    "nta = gpd.read_file(\"data/nynta2020.geojson\")  # replace path if needed\n",
    "nta = nta.to_crs(\"EPSG:4326\")  # ensure same CRS\n",
    "\n",
    "# Spatial join: fines ‚Üí neighborhoods\n",
    "joined = gpd.sjoin(gdf, nta, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "\n",
    "# Preview matched fines with neighborhood info\n",
    "print(joined[['house_number', 'street_name', 'boroname', 'ntaname']].dropna().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Cell 3: Count Fines by Neighborhood\n",
    "Here, we group the spatially joined data by ntaname (neighborhood name) and count how many fines occurred in each neighborhood.\n",
    "This gives us raw counts of violations by area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 ntaname  num_fines\n",
      "131                 Midtown-Times Square       1098\n",
      "32                  Chelsea-Hudson Yards        673\n",
      "88                     Greenwich Village        669\n",
      "204        Upper East Side-Carnegie Hill        651\n",
      "207            Upper West Side (Central)        649\n",
      "61                          East Village        626\n",
      "130  Midtown South-Flatiron-Union Square        608\n",
      "216                         West Village        603\n",
      "93                        Hell's Kitchen        493\n",
      "142                 Murray Hill-Kips Bay        488\n"
     ]
    }
   ],
   "source": [
    "# Count number of fines per neighborhood\n",
    "nta_counts = joined.groupby('ntaname').size().reset_index(name='num_fines')\n",
    "\n",
    "# Preview top 10\n",
    "print(nta_counts.sort_values(by='num_fines', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë• Cell 4: Normalize by Population\n",
    "We load NYC population data by NTA and merge it with the fine data by matching on neighborhood names.\n",
    "Then we compute fines per 1,000 residents, which normalizes the violation counts relative to population size ‚Äî giving a fairer comparison across neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           ntaname   ntaabbrev   boroname  Population  \\\n",
      "38                    East Village      EstVlg  Manhattan     41746.0   \n",
      "39                    East Village      EstVlg  Manhattan     44136.0   \n",
      "62                        Gramercy      Grmrcy  Manhattan     26184.0   \n",
      "63                        Gramercy      Grmrcy  Manhattan     27988.0   \n",
      "144  Upper East Side-Carnegie Hill  UES_CrngHl  Manhattan     61207.0   \n",
      "\n",
      "     num_fines  fines_per_1000  \n",
      "38         626       14.995449  \n",
      "39         626       14.183433  \n",
      "62         299       11.419187  \n",
      "63         299       10.683150  \n",
      "144        651       10.636038  \n"
     ]
    }
   ],
   "source": [
    "pop_df = pd.read_csv(\"data/New_York_City_Population_By_Neighborhood_Tabulation_Areas.csv\")\n",
    "\n",
    "# Strip whitespace and normalize\n",
    "joined['ntaname'] = joined['ntaname'].str.strip()\n",
    "pop_df['NTA Name'] = pop_df['NTA Name'].str.strip()\n",
    "\n",
    "# Merge using ntaname\n",
    "merged = joined.merge(pop_df, left_on='ntaname', right_on='NTA Name', how='left')\n",
    "\n",
    "# Group and compute stats\n",
    "nta_stats = (\n",
    "    merged.groupby(['ntaname', 'ntaabbrev', 'boroname', 'Population'])\n",
    "    .size()\n",
    "    .reset_index(name='num_fines')\n",
    ")\n",
    "\n",
    "nta_stats['fines_per_1000'] = (nta_stats['num_fines'] / nta_stats['Population']) * 1000\n",
    "\n",
    "# Preview\n",
    "print(nta_stats.sort_values(by='fines_per_1000', ascending=False).head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cell 5: Clean and Aggregate Neighborhood Stats\n",
    "Some neighborhoods may appear multiple times (due to data duplication or merged borders).\n",
    "This step groups by neighborhood name again and computes the mean fines per 1,000 residents for each neighborhood to get a clean final dataset for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ntaname  num_fines  Population  fines_per_1000\n",
      "19                   East Village       1252     42941.0       14.589441\n",
      "31                       Gramercy        598     27086.0       11.051169\n",
      "72  Upper East Side-Carnegie Hill       1302     62435.5       10.430799\n",
      "51           Murray Hill-Kips Bay        976     49580.5        9.847984\n",
      "73                   West Village       1206     67681.5        8.910627\n"
     ]
    }
   ],
   "source": [
    "nta_cleaned = (\n",
    "    nta_stats.groupby('ntaname')\n",
    "    .agg({\n",
    "        'num_fines': 'sum',\n",
    "        'Population': 'mean',\n",
    "        'fines_per_1000': 'mean'\n",
    "    })\n",
    "    .reset_index()\n",
    "    .sort_values(by='fines_per_1000', ascending=False)\n",
    ")\n",
    "print(nta_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned neighborhood-level stats\n",
    "nta_cleaned.to_csv(\"data/nta_fine_stats_cleaned.csv\", index=False)\n",
    "\n",
    "# Also save raw joined fine points (optional)\n",
    "joined.to_file(\"data/fines_joined_with_neighborhoods.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "# Save GeoJSON with stats merged in (for choropleth)\n",
    "geo_merged = nta.merge(nta_cleaned, on='ntaname', how='left')\n",
    "geo_merged.to_file(\"data/nta_with_fine_stats.geojson\", driver=\"GeoJSON\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
